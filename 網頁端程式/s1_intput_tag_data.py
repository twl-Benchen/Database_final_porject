import mysql.connector
import json
from datetime import datetime
import os

# è³‡æ–™åº«é€£æ¥é…ç½®
DB_CONFIG = {
    'host': 'localhost',
    'port': 3306,
    'database': 'etf_db',
    'user': 'benchen',
    'password': '000',
    'charset': 'utf8mb4'
}

# æ”¹è‰¯ç‰ˆæ¨™ç±¤è³‡æ–™ - æ›´æ¸…æ¥šçš„éšå±¤çµæ§‹
DETAILED_TAGS_MAP = {
    "è‚¡ç¥¨å‹": {
        "å­åˆ†é¡": ["å¤§å‹æ¬Šå€¼", "ä¸­å°å‹æ¬Šå€¼", "å› å­æŠ•è³‡", "ä¸»å‹•å¼", "ESG", "ç­‰æ¬Šé‡"],
    },
    "é«˜è‚¡æ¯": {
        "ç‰¹æ€§": ["é«˜æ¯ä½æ³¢å‹•", "ESG"],
        "é…æ¯é »ç‡": ["æœˆé…", "å­£é…", "åŠå¹´é…"],
    },
    "å‚µåˆ¸å‹": {
        "æœŸé™": ["é•·å‚µ", "ä¸­é•·å‚µ", "ä¸­çŸ­å‚µ"],
        "é¡å‹": ["ä¸»æ¬Šå‚µ", "é‡‘èå‚µ", "å…¬å‚µ", "æŠ•ç­‰å‚µ"],
        "åœ°å€": ["å…¨çƒå‚µ", "ç¾å‚µ", "äºå‚µ", "æ–°èˆˆå¸‚å ´å‚µ", "æ­å‚µ", "ä¸­åœ‹å‚µ"],
        "ç‰¹æ€§": ["æ§“æ¡¿å‹"],
        "é…æ¯": ["æœˆé…", "å­£é…", "åŠå¹´é…"]
    },
    "ä¸»é¡Œ": ["ä¸å‹•ç”¢", "ç”ŸæŠ€", "ç§‘æŠ€", "ç¶ èƒ½", "é‡‘è", "é›»ä¿¡é€šè¨Š", "é›»å‹•è»Š", "åŠå°é«”", "ESG"],
    "æŠ•ä¿¡": ["å…ƒå¤§", "å¯Œé‚¦", "æ°¸è±", "å…†è±", "åœ‹æ³°", "ç¬¬ä¸€é‡‘", "å¾©è¯", "ç¾¤ç›Š", "æ–°å…‰", "å°æ–°", 
            "ä¸­åœ‹ä¿¡è¨—", "çµ±ä¸€", "è¡—å£", "å¯Œè˜­å…‹æ—", "å‡±åŸº", "å¤§è¯éŠ€", "é‡æ‘", "ä¿å¾·ä¿¡", "è¯é‚¦"],
    "å…¶ä»–": ["æ§“æ¡¿å‹", "åå‘å‹", "è²¨å¹£å‹", "åŠ æ¬ŠæŒ‡æ•¸", "æœŸè²¨å‹(åŸç‰©æ–™)"],
    "é…æ¯æœˆä»½": ["1æœˆ", "2æœˆ", "3æœˆ", "4æœˆ", "5æœˆ", "6æœˆ", "7æœˆ", "8æœˆ", "9æœˆ", "10æœˆ", "11æœˆ", "12æœˆ"]
}

def connect_to_db():
    """å»ºç«‹è³‡æ–™åº«é€£æ¥"""
    try:
        connection = mysql.connector.connect(**DB_CONFIG)
        if connection.is_connected():
            print("âœ… è³‡æ–™åº«é€£æ¥æˆåŠŸ")
            return connection
        else:
            print("âŒ è³‡æ–™åº«é€£æ¥å¤±æ•—")
            return None
    except mysql.connector.Error as err:
        print(f"âŒ è³‡æ–™åº«é€£æ¥éŒ¯èª¤: {err}")
        return None

def flatten_tags_map(tags_map):
    """å°‡å·¢ç‹€çš„æ¨™ç±¤çµæ§‹å±•é–‹ç‚ºå¹³é¢çµæ§‹"""
    flattened = {}
    
    for parent_tag, children in tags_map.items():
        if isinstance(children, dict):
            # å¦‚æœå­é …ç›®æ˜¯å­—å…¸ï¼Œå°‡æ‰€æœ‰å­åˆ†é¡åˆä½µ
            all_children = []
            for sub_category, sub_items in children.items():
                all_children.extend(sub_items)
            flattened[parent_tag] = all_children
        else:
            # å¦‚æœå­é …ç›®æ˜¯åˆ—è¡¨ï¼Œç›´æ¥ä½¿ç”¨
            flattened[parent_tag] = children
    
    return flattened

def check_existing_data(connection, table_name):
    """æª¢æŸ¥è³‡æ–™è¡¨ä¸­æ˜¯å¦å·²æœ‰è³‡æ–™"""
    cursor = connection.cursor()
    try:
        cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
        count = cursor.fetchone()[0]
        return count
    except Exception as e:
        print(f"âŒ æª¢æŸ¥ {table_name} è³‡æ–™å¤±æ•—: {e}")
        return 0
    finally:
        cursor.close()

def clear_existing_data(connection, clear_type="all"):
    """æ¸…é™¤ç¾æœ‰è³‡æ–™ - æ”¹è‰¯ç‰ˆï¼Œè™•ç†å¤–éµç´„æŸ"""
    cursor = connection.cursor()
    
    try:
        print(f"ğŸ—‘ï¸  é–‹å§‹æ¸…é™¤ {clear_type} è³‡æ–™...")
        
        # æš«æ™‚åœç”¨å¤–éµæª¢æŸ¥
        cursor.execute("SET FOREIGN_KEY_CHECKS = 0")
        
        if clear_type in ["all", "tags"]:
            # æŒ‰ç…§ä¾è³´é †åºæ¸…é™¤æ¨™ç±¤ç›¸é—œè³‡æ–™
            tables_to_clear = ["ETF_Category", "Category_Level2", "Category_Level1"]
            for table in tables_to_clear:
                cursor.execute(f"DELETE FROM {table}")
                print(f"  âœ… å·²æ¸…é™¤ {table}")
        
        if clear_type in ["all", "etf"]:
            # æ¸…é™¤ETFç›¸é—œè³‡æ–™
            cursor.execute("DELETE FROM ETF_Category")
            cursor.execute("DELETE FROM Portfolio") 
            cursor.execute("DELETE FROM Transaction")
            cursor.execute("DELETE FROM ETF_HistoryPrice")
            cursor.execute("DELETE FROM ETF")
            print("  âœ… å·²æ¸…é™¤ETFç›¸é—œè³‡æ–™")
        
        # é‡æ–°å•Ÿç”¨å¤–éµæª¢æŸ¥
        cursor.execute("SET FOREIGN_KEY_CHECKS = 1")
        
        connection.commit()
        print("ğŸ—‘ï¸  è³‡æ–™æ¸…é™¤å®Œæˆ")
        return True
        
    except Exception as e:
        print(f"âŒ æ¸…é™¤è³‡æ–™å¤±æ•—: {e}")
        cursor.execute("SET FOREIGN_KEY_CHECKS = 1")  # ç¢ºä¿é‡æ–°å•Ÿç”¨å¤–éµæª¢æŸ¥
        connection.rollback()
        return False
    finally:
        cursor.close()

def clean_duplicate_etf_data(connection):
    """æ¸…ç†é‡è¤‡çš„ETFè³‡æ–™"""
    cursor = connection.cursor()
    
    try:
        print("ğŸ§¹ æ­£åœ¨æ¸…ç†é‡è¤‡çš„ETFè³‡æ–™...")
        
        # æ‰¾å‡ºé‡è¤‡çš„ETFè¨˜éŒ„ï¼ˆä¿ç•™æœ€æ–°çš„ä¸€ç­†ï¼‰
        cleanup_query = """
        DELETE e1 FROM ETF e1
        INNER JOIN ETF e2 
        WHERE e1.ETF_Id = e2.ETF_Id AND e1.ETF_Created_At < e2.ETF_Created_At
        """
        
        cursor.execute(cleanup_query)
        deleted_count = cursor.rowcount
        
        connection.commit()
        print(f"âœ… å·²æ¸…ç† {deleted_count} ç­†é‡è¤‡çš„ETFè³‡æ–™")
        return True
        
    except Exception as e:
        print(f"âŒ æ¸…ç†é‡è¤‡è³‡æ–™å¤±æ•—: {e}")
        connection.rollback()
        return False
    finally:
        cursor.close()

def insert_tags_improved(connection):
    """æ”¹è‰¯ç‰ˆæ¨™ç±¤æ’å…¥å‡½æ•¸"""
    cursor = connection.cursor()
    
    try:
        # å±•é–‹å·¢ç‹€æ¨™ç±¤çµæ§‹
        flat_tags = flatten_tags_map(DETAILED_TAGS_MAP)
        
        print("ğŸ“ é–‹å§‹æ’å…¥æ¨™ç±¤è³‡æ–™...")
        print(f"å…±æœ‰ {len(flat_tags)} å€‹çˆ¶åˆ†é¡")
        
        # æ’å…¥ç¬¬ä¸€å±¤åˆ†é¡ï¼ˆçˆ¶æ¨™ç±¤ï¼‰
        insert_level1_query = "INSERT INTO Category_Level1 (Category1_Name) VALUES (%s)"
        level1_ids = {}
        
        for parent_tag in flat_tags.keys():
            try:
                cursor.execute(insert_level1_query, (parent_tag,))
                level1_id = cursor.lastrowid
                level1_ids[parent_tag] = level1_id
                print(f"  âœ… æ’å…¥çˆ¶åˆ†é¡: {parent_tag} (ID: {level1_id})")
            except mysql.connector.IntegrityError as e:
                print(f"  âš ï¸  çˆ¶åˆ†é¡ {parent_tag} å¯èƒ½å·²å­˜åœ¨: {e}")
                continue
        
        connection.commit()
        print("ğŸ“‹ ç¬¬ä¸€å±¤åˆ†é¡æ’å…¥å®Œæˆ")
        
        # æ’å…¥ç¬¬äºŒå±¤åˆ†é¡ï¼ˆå­æ¨™ç±¤ï¼‰
        print("\nğŸ“ é–‹å§‹æ’å…¥ç¬¬äºŒå±¤åˆ†é¡...")
        insert_level2_query = "INSERT INTO Category_Level2 (Category1_Id, Category2_Name) VALUES (%s, %s)"
        
        total_level2_count = 0
        level2_ids = {}  # å„²å­˜å­åˆ†é¡IDï¼Œæ–¹ä¾¿å¾ŒçºŒä½¿ç”¨
        
        for parent_tag, child_tags in flat_tags.items():
            if parent_tag not in level1_ids:
                print(f"  âš ï¸  æ‰¾ä¸åˆ°çˆ¶åˆ†é¡ {parent_tag} çš„IDï¼Œè·³éå…¶å­åˆ†é¡")
                continue
                
            parent_id = level1_ids[parent_tag]
            print(f"\n  è™•ç† '{parent_tag}' çš„å­åˆ†é¡ ({len(child_tags)} å€‹):")
            
            for child_tag in child_tags:
                try:
                    cursor.execute(insert_level2_query, (parent_id, child_tag))
                    level2_id = cursor.lastrowid
                    level2_ids[child_tag] = level2_id
                    print(f"    âœ… {child_tag} (ID: {level2_id})")
                    total_level2_count += 1
                except mysql.connector.IntegrityError as e:
                    print(f"    âš ï¸  å­åˆ†é¡ {child_tag} å¯èƒ½å·²å­˜åœ¨: {e}")
                    continue
        
        connection.commit()
        print(f"\nğŸ“‹ ç¬¬äºŒå±¤åˆ†é¡æ’å…¥å®Œæˆï¼Œå…± {total_level2_count} å€‹å­åˆ†é¡")
        
        return True, level1_ids, level2_ids
        
    except Exception as e:
        print(f"âŒ æ’å…¥æ¨™ç±¤è³‡æ–™å¤±æ•—: {e}")
        connection.rollback()
        return False, {}, {}
    finally:
        cursor.close()

def get_category_mapping(connection):
    """å–å¾—åˆ†é¡åç¨±èˆ‡IDçš„å°æ‡‰é—œä¿‚"""
    cursor = connection.cursor()
    
    try:
        query = """
        SELECT c2.Category2_Name, c2.Category2_Id, c1.Category1_Name
        FROM Category_Level2 c2
        JOIN Category_Level1 c1 ON c2.Category1_Id = c1.Category1_Id
        """
        cursor.execute(query)
        results = cursor.fetchall()
        
        # å»ºç«‹åç¨±åˆ°IDçš„å°æ‡‰å­—å…¸
        category_map = {}
        parent_map = {}
        
        for child_name, child_id, parent_name in results:
            category_map[child_name] = child_id
            parent_map[child_name] = parent_name
            
        print(f"âœ… å–å¾— {len(category_map)} å€‹åˆ†é¡å°æ‡‰é—œä¿‚")
        return category_map, parent_map
        
    except Exception as e:
        print(f"âŒ å–å¾—åˆ†é¡å°æ‡‰é—œä¿‚å¤±æ•—: {e}")
        return {}, {}
    finally:
        cursor.close()

def parse_scale(scale_str):
    """è§£æè¦æ¨¡å­—ä¸²ï¼Œå°‡å…¶è½‰æ›ç‚ºæ•´æ•¸ï¼ˆä»¥å„„ç‚ºå–®ä½ï¼‰"""
    if not scale_str or scale_str == 'N/A':
        return 0
    
    # ç§»é™¤é€—è™Ÿ
    scale_str = scale_str.replace(',', '')
    
    try:
        return int(float(scale_str))
    except ValueError:
        return 0

def parse_holders(holders_str):
    """è§£ææŒæœ‰äººæ•¸å­—ä¸²"""
    if not holders_str or holders_str == 'N/A':
        return 0
    
    # ç§»é™¤é€—è™Ÿ
    holders_str = holders_str.replace(',', '')
    
    try:
        return int(float(holders_str))
    except ValueError:
        return 0

def parse_date(date_str):
    """è§£ææ—¥æœŸå­—ä¸²ï¼Œè½‰æ›ç‚º MySQL æ—¥æœŸæ ¼å¼"""
    try:
        # å‡è¨­è¼¸å…¥æ ¼å¼ç‚º "2003/06/30"
        return datetime.strptime(date_str, "%Y/%m/%d").date()
    except ValueError:
        try:
            # å˜—è©¦å…¶ä»–å¯èƒ½çš„æ ¼å¼
            return datetime.strptime(date_str, "%Y-%m-%d").date()
        except ValueError:
            # å¦‚æœè§£æå¤±æ•—ï¼Œè¿”å›é è¨­æ—¥æœŸ
            return datetime(2000, 1, 1).date()

def insert_etf_data_improved(connection, json_file_path):
    """æ”¹è‰¯ç‰ˆETFè³‡æ–™æ’å…¥å‡½æ•¸"""
    
    # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
    if not os.path.exists(json_file_path):
        print(f"âŒ æ‰¾ä¸åˆ°æª”æ¡ˆ: {json_file_path}")
        current_dir = os.getcwd()
        print(f"ç›®å‰å·¥ä½œç›®éŒ„: {current_dir}")
        print("è«‹ç¢ºèªæª”æ¡ˆè·¯å¾‘æ˜¯å¦æ­£ç¢º")
        return False
    
    # è®€å–JSONæª”æ¡ˆ
    try:
        with open(json_file_path, 'r', encoding='utf-8') as file:
            etf_data = json.load(file)
        print(f"ğŸ“‚ æˆåŠŸè®€å– {len(etf_data)} ç­†ETFè³‡æ–™")
    except Exception as e:
        print(f"âŒ è®€å–JSONæª”æ¡ˆå¤±æ•—: {e}")
        return False
    
    # å–å¾—åˆ†é¡å°æ‡‰é—œä¿‚
    category_map, parent_map = get_category_mapping(connection)
    if not category_map:
        print("âŒ ç„¡æ³•å–å¾—åˆ†é¡å°æ‡‰é—œä¿‚ï¼Œè«‹å…ˆæ’å…¥æ¨™ç±¤è³‡æ–™")
        return False
    
    cursor = connection.cursor()
    
    try:
        # æº–å‚™æ’å…¥ETFçš„SQLèªå¥
        insert_etf_query = """
        INSERT INTO ETF (ETF_Id, ETF_Name, Holders, IndexName, Scale, ETF_Created_At) 
        VALUES (%s, %s, %s, %s, %s, %s)
        ON DUPLICATE KEY UPDATE
        ETF_Name = VALUES(ETF_Name),
        Holders = VALUES(Holders),
        IndexName = VALUES(IndexName),
        Scale = VALUES(Scale),
        ETF_Created_At = VALUES(ETF_Created_At)
        """
        
        # æº–å‚™æ’å…¥ETFåˆ†é¡é—œè¯çš„SQLèªå¥
        insert_category_query = """
        INSERT IGNORE INTO ETF_Category (ETF_Id, Category2_Id) VALUES (%s, %s)
        """
        
        success_count = 0
        error_count = 0
        total_categories = 0
        skipped_tags = set()
        
        print("\nğŸ“Š é–‹å§‹æ’å…¥ETFè³‡æ–™...")
        
        for i, etf in enumerate(etf_data, 1):
            try:
                # è§£æETFåŸºæœ¬è³‡æ–™
                etf_id = etf.get('stockNo', '')
                etf_name = etf.get('stockName', '')
                holders = parse_holders(etf.get('holders', '0'))
                index_name = etf.get('indexName', 'N/A')
                scale = parse_scale(etf.get('totalAv_100million', '0'))
                created_date = parse_date(etf.get('listingDate', '2000/01/01'))
                
                if not etf_id or not etf_name:
                    print(f"  âš ï¸  ETF ID æˆ–åç¨±ç‚ºç©ºï¼Œè·³éç¬¬ {i} ç­†è³‡æ–™")
                    error_count += 1
                    continue
                
                # æ’å…¥ETFåŸºæœ¬è³‡æ–™
                cursor.execute(insert_etf_query, (
                    etf_id, etf_name, holders, index_name, scale, created_date
                ))
                
                # æ’å…¥æ‰€æœ‰ç›¸é—œçš„åˆ†é¡é—œè¯
                tags = etf.get('tags', [])
                category_inserted = 0
                
                for tag in tags:
                    if tag in category_map:
                        category_id = category_map[tag]
                        cursor.execute(insert_category_query, (etf_id, category_id))
                        category_inserted += 1
                        total_categories += 1
                    else:
                        skipped_tags.add(tag)
                
                print(f"  âœ… [{i:3d}/{len(etf_data)}] {etf_id} - {etf_name} (æ¨™ç±¤: {category_inserted}å€‹)")
                success_count += 1
                
                # æ¯100ç­†æäº¤ä¸€æ¬¡ï¼Œé¿å…è¨˜æ†¶é«”å•é¡Œ
                if i % 100 == 0:
                    connection.commit()
                    print(f"    ğŸ’¾ å·²æäº¤å‰ {i} ç­†è³‡æ–™")
                
            except mysql.connector.IntegrityError as e:
                if "Duplicate entry" in str(e):
                    print(f"  âš ï¸  ETF {etf.get('stockNo', 'Unknown')} å·²å­˜åœ¨ï¼Œæ›´æ–°è³‡æ–™")
                else:
                    print(f"  âŒ ETF {etf.get('stockNo', 'Unknown')} è³‡æ–™å®Œæ•´æ€§éŒ¯èª¤: {e}")
                    error_count += 1
            except Exception as e:
                print(f"  âŒ æ’å…¥ETF {etf.get('stockNo', 'Unknown')} å¤±æ•—: {e}")
                error_count += 1
                continue
        
        # æœ€çµ‚æäº¤
        connection.commit()
        
        print(f"\nğŸ“Š ETFè³‡æ–™æ’å…¥å®Œæˆ:")
        print(f"  æˆåŠŸ: {success_count} ç­†ETF")
        print(f"  å¤±æ•—: {error_count} ç­†ETF")
        print(f"  æ¨™ç±¤é—œè¯: {total_categories} ç­†")
        
        if skipped_tags:
            print(f"\nâš ï¸  æœªæ‰¾åˆ°å°æ‡‰çš„æ¨™ç±¤ ({len(skipped_tags)} å€‹):")
            for tag in sorted(skipped_tags):
                print(f"    - {tag}")
            print("  å»ºè­°æª¢æŸ¥æ¨™ç±¤è³‡æ–™æˆ–æ›´æ–° DETAILED_TAGS_MAP")
        
        return success_count > 0
        
    except Exception as e:
        print(f"âŒ æ’å…¥ETFè³‡æ–™éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
        connection.rollback()
        return False
        
    finally:
        cursor.close()

def verify_tag_insertion(connection):
    """é©—è­‰æ¨™ç±¤æ’å…¥çµæœ"""
    cursor = connection.cursor()
    
    try:
        print("\nğŸ” é©—è­‰æ¨™ç±¤æ’å…¥çµæœ...")
        
        # æª¢æŸ¥ç¬¬ä¸€å±¤åˆ†é¡
        cursor.execute("SELECT Category1_Id, Category1_Name FROM Category_Level1 ORDER BY Category1_Id")
        level1_results = cursor.fetchall()
        
        print(f"\nç¬¬ä¸€å±¤åˆ†é¡ ({len(level1_results)} å€‹):")
        for id, name in level1_results:
            print(f"  ID: {id}, åç¨±: {name}")
        
        # æª¢æŸ¥ç¬¬äºŒå±¤åˆ†é¡çµ±è¨ˆ
        query = """
        SELECT c1.Category1_Name, COUNT(c2.Category2_Id) as count
        FROM Category_Level1 c1
        LEFT JOIN Category_Level2 c2 ON c1.Category1_Id = c2.Category1_Id
        GROUP BY c1.Category1_Id, c1.Category1_Name
        ORDER BY c1.Category1_Id
        """
        cursor.execute(query)
        level2_stats = cursor.fetchall()
        
        print(f"\nç¬¬äºŒå±¤åˆ†é¡çµ±è¨ˆ:")
        total_level2 = 0
        for parent, count in level2_stats:
            print(f"  {parent}: {count} å€‹å­åˆ†é¡")
            total_level2 += count
        
        print(f"ç¸½è¨ˆç¬¬äºŒå±¤åˆ†é¡: {total_level2} å€‹")
        
        return True
        
    except Exception as e:
        print(f"âŒ é©—è­‰æ¨™ç±¤æ’å…¥å¤±æ•—: {e}")
        return False
    finally:
        cursor.close()

def show_detailed_summary(connection):
    """é¡¯ç¤ºè©³ç´°çš„è³‡æ–™åº«æ‘˜è¦"""
    cursor = connection.cursor()
    
    try:
        print("\nğŸ“Š è©³ç´°è³‡æ–™åº«æ‘˜è¦:")
        print("=" * 60)
        
        # æ¨™ç±¤çµ±è¨ˆ
        cursor.execute("SELECT COUNT(*) FROM Category_Level1")
        level1_count = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(*) FROM Category_Level2") 
        level2_count = cursor.fetchone()[0]
        
        print(f"æ¨™ç±¤ç³»çµ±:")
        print(f"  ç¬¬ä¸€å±¤åˆ†é¡: {level1_count} å€‹")
        print(f"  ç¬¬äºŒå±¤åˆ†é¡: {level2_count} å€‹")
        
        # ETFçµ±è¨ˆ
        cursor.execute("SELECT COUNT(*) FROM ETF")
        etf_count = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(*) FROM ETF_Category")
        category_relation_count = cursor.fetchone()[0]
        
        print(f"\nETFè³‡æ–™:")
        print(f"  ETFç¸½æ•¸: {etf_count} æ”¯")
        print(f"  æ¨™ç±¤é—œè¯: {category_relation_count} ç­†")
        
        if etf_count > 0:
            avg_tags = category_relation_count / etf_count
            print(f"  å¹³å‡æ¯æ”¯ETFæ¨™ç±¤æ•¸: {avg_tags:.1f} å€‹")
        
        # å„åˆ†é¡çš„ETFæ•¸é‡çµ±è¨ˆ
        if etf_count > 0:
            query = """
            SELECT c1.Category1_Name, COUNT(DISTINCT ec.ETF_Id) as etf_count
            FROM Category_Level1 c1
            LEFT JOIN Category_Level2 c2 ON c1.Category1_Id = c2.Category1_Id
            LEFT JOIN ETF_Category ec ON c2.Category2_Id = ec.Category2_Id
            GROUP BY c1.Category1_Id, c1.Category1_Name
            ORDER BY etf_count DESC
            """
            cursor.execute(query)
            category_stats = cursor.fetchall()
            
            print(f"\nå„åˆ†é¡ETFæ•¸é‡:")
            for category, count in category_stats:
                print(f"  {category}: {count} æ”¯ETF")
        
    except Exception as e:
        print(f"âŒ æŸ¥è©¢æ‘˜è¦è³‡æ–™å¤±æ•—: {e}")
    finally:
        cursor.close()

def main():
    """ä¸»ç¨‹å¼ - å®Œæ•´ç‰ˆ"""
    print("ğŸ·ï¸  ETFæ¨™ç±¤èˆ‡è³‡æ–™æ’å…¥å·¥å…· (å®Œæ•´ç‰ˆ)")
    print("=" * 60)
    
    # å»ºç«‹è³‡æ–™åº«é€£æ¥
    connection = connect_to_db()
    if not connection:
        print("âŒ ç„¡æ³•é€£æ¥è³‡æ–™åº«ï¼Œç¨‹å¼çµæŸ")
        return
    
    try:
        # æª¢æŸ¥ç¾æœ‰è³‡æ–™
        existing_level1 = check_existing_data(connection, "Category_Level1")
        existing_level2 = check_existing_data(connection, "Category_Level2")
        existing_etf = check_existing_data(connection, "ETF")
        existing_relations = check_existing_data(connection, "ETF_Category")
        
        print(f"\nğŸ“‹ ç¾æœ‰è³‡æ–™ç‹€æ³:")
        print(f"  ç¬¬ä¸€å±¤åˆ†é¡: {existing_level1} å€‹")
        print(f"  ç¬¬äºŒå±¤åˆ†é¡: {existing_level2} å€‹") 
        print(f"  ETFè³‡æ–™: {existing_etf} æ”¯")
        print(f"  æ¨™ç±¤é—œè¯: {existing_relations} ç­†")
        
        # ç¬¬ä¸€æ­¥ï¼šè™•ç†æ¨™ç±¤è³‡æ–™
        print(f"\nğŸ·ï¸  ç¬¬ä¸€æ­¥ï¼šæ¨™ç±¤è³‡æ–™è™•ç†")
        print("-" * 30)
        
        tags_ready = False
        
        if existing_level1 > 0 or existing_level2 > 0:
            print("âš ï¸  ç™¼ç¾ç¾æœ‰æ¨™ç±¤è³‡æ–™")
            choice = input("é¸æ“‡æ“ä½œ (1:æ¸…é™¤é‡å»º 2:è·³éæ¨™ç±¤æ’å…¥ 3:æŸ¥çœ‹ç¾æœ‰æ¨™ç±¤): ").strip()
            
            if choice == "1":
                if clear_existing_data(connection, "tags"):
                    success, level1_ids, level2_ids = insert_tags_improved(connection)
                    if success:
                        verify_tag_insertion(connection)
                        tags_ready = True
                else:
                    print("âŒ æ¸…é™¤è³‡æ–™å¤±æ•—")
                    return
            elif choice == "3":
                verify_tag_insertion(connection)
                tags_ready = True
            else:
                print("â­ï¸  è·³éæ¨™ç±¤æ’å…¥")
                tags_ready = True
        else:
            print("ğŸ†• é–‹å§‹æ’å…¥æ¨™ç±¤è³‡æ–™...")
            success, level1_ids, level2_ids = insert_tags_improved(connection)
            if success:
                verify_tag_insertion(connection)
                tags_ready = True
            else:
                print("âŒ æ¨™ç±¤æ’å…¥å¤±æ•—")
                return
        
        # ç¬¬äºŒæ­¥ï¼šè™•ç†ETFè³‡æ–™
        if tags_ready:
            print(f"\nğŸ“Š ç¬¬äºŒæ­¥ï¼šETFè³‡æ–™è™•ç†")
            print("-" * 30)
            
            # æª¢æŸ¥æ˜¯å¦éœ€è¦æ¸…ç†é‡è¤‡è³‡æ–™
            cursor = connection.cursor()
            cursor.execute("SELECT ETF_Id, COUNT(*) FROM ETF GROUP BY ETF_Id HAVING COUNT(*) > 1")
            duplicates = cursor.fetchall()
            cursor.close()
            
            if duplicates:
                print(f"âš ï¸  ç™¼ç¾ {len(duplicates)} å€‹ETFæœ‰é‡è¤‡è³‡æ–™")
                clean_duplicates = input("æ˜¯å¦è¦æ¸…ç†é‡è¤‡çš„ETFè³‡æ–™? (y/n): ").lower().strip()
                if clean_duplicates == 'y':
                    clean_duplicate_etf_data(connection)
            
            # è©¢å•JSONæª”æ¡ˆè·¯å¾‘
            json_file_path = input("è«‹è¼¸å…¥ combined_etf_data.json çš„å®Œæ•´è·¯å¾‘ (ç›´æ¥æŒ‰Enterä½¿ç”¨é è¨­è·¯å¾‘): ").strip()
            if not json_file_path:
                json_file_path = "combined_etf_data.json"  # é è¨­æª”å
            
            # ç¢ºèªæ˜¯å¦è¦è™•ç†ETFè³‡æ–™
            if existing_etf > 0:
                print(f"âš ï¸  ç™¼ç¾ç¾æœ‰ {existing_etf} æ”¯ETFè³‡æ–™")
                etf_choice = input("é¸æ“‡æ“ä½œ (1:æ¸…é™¤ä¸¦é‡æ–°æ’å…¥ 2:æ›´æ–°ç¾æœ‰è³‡æ–™ 3:è·³éETFæ’å…¥): ").strip()
                
                if etf_choice == "1":
                    if clear_existing_data(connection, "etf"):
                        if insert_etf_data_improved(connection, json_file_path):
                            print("\nğŸ‰ ETFè³‡æ–™æ’å…¥æˆåŠŸ!")
                        else:
                            print("\nâŒ ETFè³‡æ–™æ’å…¥å¤±æ•—")
                elif etf_choice == "2":
                    if insert_etf_data_improved(connection, json_file_path):
                        print("\nğŸ‰ ETFè³‡æ–™æ›´æ–°æˆåŠŸ!")
                    else:
                        print("\nâŒ ETFè³‡æ–™æ›´æ–°å¤±æ•—")
                else:
                    print("â­ï¸  è·³éETFè³‡æ–™æ’å…¥")
            else:
                # æ²’æœ‰ç¾æœ‰ETFè³‡æ–™ï¼Œç›´æ¥æ’å…¥
                if insert_etf_data_improved(connection, json_file_path):
                    print("\nğŸ‰ ETFè³‡æ–™æ’å…¥æˆåŠŸ!")
                else:
                    print("\nâŒ ETFè³‡æ–™æ’å…¥å¤±æ•—")
        
        # ç¬¬ä¸‰æ­¥ï¼šé¡¯ç¤ºæœ€çµ‚æ‘˜è¦
        print(f"\nğŸ“Š ç¬¬ä¸‰æ­¥ï¼šæœ€çµ‚æ‘˜è¦")
        print("-" * 30)
        show_detailed_summary(connection)
        
        print("\nâœ… ç¨‹å¼åŸ·è¡Œå®Œæˆï¼")
        
        # æä¾›å¾ŒçºŒæ“ä½œå»ºè­°
        print("\nğŸ’¡ å¾ŒçºŒå¯ä»¥åŸ·è¡Œçš„æ“ä½œ:")
        print("  1. æŸ¥è©¢ç‰¹å®šåˆ†é¡çš„ETF: SELECT * FROM ETF WHERE ETF_Id IN (...)")
        print("  2. çµ±è¨ˆå„æ¨™ç±¤çš„ä½¿ç”¨æƒ…æ³")
        print("  3. åˆ†æETFçš„æ¨™ç±¤åˆ†å¸ƒ")
        print("  4. å»ºç«‹ETFæ¨è–¦ç³»çµ±")
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç¨‹å¼è¢«ä½¿ç”¨è€…ä¸­æ–·")
    except Exception as e:
        print(f"\nâŒ ç¨‹å¼åŸ·è¡ŒéŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
    finally:
        if connection and connection.is_connected():
            connection.close()
            print("\nğŸ‘‹ è³‡æ–™åº«é€£æ¥å·²é—œé–‰ï¼Œç¨‹å¼çµæŸ")

if __name__ == "__main__":
    main()